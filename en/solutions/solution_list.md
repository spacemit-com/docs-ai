sidebar_position: 1

# Solution Overview

## AI Chatbot

This use case showcases an AI chatbot created by seamlessly connecting a voice module with large language models. The system supports clear, coherent multi-turn conversations and provides accurate information and answers through deep natural language understanding.

### Project Highlights

- **Models Used**: SenseVoice, DeepSeek R1, MeloTTS  
- **Language Support**: Python sample code provided  
- **Key Features**: End-to-end voice input and voice output

[Learn more](https://bianbu.spacemit.com/brdk/Robot_development/6.5_Robot_Application_Cases/6.5.3_large-language-model/ai-chat)

## Intelligent AGV Following Robot

This use case demonstrates an AGV robot that combines multimodal interaction with autonomous mobility. Users can control the robot through voice commands, while real-time visual perception enables precise human-following behavior. A large language model uses the Function Call mechanism together with the ROS2 framework to intelligently coordinate robot motion. By integrating perception, motion planning, and voice interaction, this solution highlights the practical value of intelligent AGVs in home service and industrial automation scenarios.

### Project Highlights

- **Models Used**: Qwen2.5-0.5B, YOLOv8  
- **Language Support**: Python sample code provided  
- **Key Features**: Voice control, YOLOv8-based object detection, LLM callback–driven intelligent following

[Learn more](https://bianbu.spacemit.com/brdk/Robot_development/6.5_Robot_Application_Cases/6.5.1_human-robot-interaction/agv-follow)

## Smart Retail Robotic Arm

This use case introduces a smart retail solution powered by the K1 platform and an Elephant robotic arm. The system brings together LLM-based interaction via Function Call, high-accuracy YOLOv8 object detection, and OCR text recognition to support a fully automated workflow—from product identification and barcode scanning to checkout and voice interaction. The solution improves automation and operational efficiency in retail environments, while also offering a clear technical path toward future smart stores and demonstrating the potential of human–machine collaboration in modern retail.

### Project Highlights

- **Models Used**: SenseVoice, Qwen2.5-0.5B, YOLOv8, PaddleOCR  
- **Language Support**: Python sample code provided  
- **Key Features**: Voice control, LLM callbacks, YOLOv8 object detection, text recognition

[Learn more](https://bianbu.spacemit.com/brdk/Robot_development/6.5_Robot_Application_Cases/6.5.1_human-robot-interaction/smart-retail)

## LeRobot Robotic Arm

This use case provides a complete end-to-end guide for deploying and running the LeRobot framework on the K1 platform, enabling intelligent robotic arm control and real-world application development. It covers the full workflow, including data collection, ACT model training and deployment, as well as fine-tuning and distributed deployment of the SmolVLA model.

## Project Highlights

- **Models Used**: ACT, SmolVLA  
- **Language Support**: Python sample code provided  
- **Key Features**: Data collection, model training, and distributed deployment

[Learn more](https://bianbu.spacemit.com/brdk/Robot_development/6.4_Robot_Application_Module/6.4.4_AI_Robotic_Arm/lerobot)
